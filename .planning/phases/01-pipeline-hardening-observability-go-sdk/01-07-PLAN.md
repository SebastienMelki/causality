---
phase: 01-pipeline-hardening-observability-go-sdk
plan: 07
type: execute
wave: 3
depends_on: ["01-01", "01-02"]
files_modified:
  - internal/compaction/module.go
  - internal/compaction/internal/service/compaction_service.go
  - internal/compaction/internal/service/scheduler.go
  - cmd/warehouse-sink/main.go
autonomous: true

must_haves:
  truths:
    - "Compaction merges small Parquet files into larger ones (target: 128-256 MB)"
    - "Compaction only processes partitions older than current hour (cold partitions)"
    - "Old small files deleted after successful merge"
    - "Compaction runs on configurable schedule (default: hourly)"
    - "Compaction is idempotent (safe to re-run)"
    - "CompactionRuns metric incremented on each compaction run"
  artifacts:
    - path: "internal/compaction/module.go"
      provides: "Compaction module facade"
      exports: ["Module", "New"]
    - path: "internal/compaction/internal/service/compaction_service.go"
      provides: "Compaction merge logic"
      contains: "MergeRowGroups"
    - path: "internal/compaction/internal/service/scheduler.go"
      provides: "Scheduled compaction runner"
      contains: "ticker"
  key_links:
    - from: "internal/compaction/internal/service/compaction_service.go"
      to: "parquet-go/parquet-go"
      via: "parquet.MergeRowGroups for merging row groups"
      pattern: "MergeRowGroups"
    - from: "internal/compaction/internal/service/compaction_service.go"
      to: "internal/warehouse/s3.go"
      via: "uses S3 client for listing, downloading, uploading, deleting files"
      pattern: "s3Client"
---

<objective>
Create the Parquet compaction module that merges small files into larger ones on a scheduled basis, targeting 128-256 MB files.

Purpose: R1.3 requires compaction to reduce small file count for query performance. The warehouse sink produces many small Parquet files (especially at low volume or with multiple worker instances), which degrades Trino query performance.
Output: `internal/compaction/` module with merge logic and scheduler. Integrated into warehouse-sink main.
</objective>

<execution_context>
@/Users/sebastienmelki/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastienmelki/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-pipeline-hardening-observability-go-sdk/01-RESEARCH.md
@.planning/phases/01-pipeline-hardening-observability-go-sdk/01-01-SUMMARY.md
@.planning/phases/01-pipeline-hardening-observability-go-sdk/01-02-SUMMARY.md
@internal/warehouse/s3.go
@internal/warehouse/parquet.go
@internal/warehouse/config.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create compaction service with Parquet merge logic</name>
  <files>
    internal/compaction/internal/service/compaction_service.go
    internal/compaction/module.go
  </files>
  <action>
    **Create `internal/compaction/internal/service/compaction_service.go`:**
    - `CompactionService` struct:
      - `s3Client` (reuse or wrap `internal/warehouse.S3Client` — use an interface for testability)
      - `targetSize int64` (target merged file size, default: 128 * 1024 * 1024)
      - `minFiles int` (minimum files in partition before compaction, default: 2)
      - `metrics *observability.Metrics`
      - `logger *slog.Logger`

    - `ListPartitions(ctx context.Context) ([]string, error)`:
      - List all "directories" (prefixes) in the S3 bucket
      - Filter to partitions older than current hour (cold partitions only — avoid compacting hot partition being actively written to)
      - Partition path format: `{app_id}/year={YYYY}/month={MM}/day={DD}/hour={HH}/`
      - Parse hour from path, skip if hour >= current UTC hour

    - `CompactPartition(ctx context.Context, partition string) error`:
      1. List all .parquet files in the partition via S3 ListObjectsV2
      2. Filter to files smaller than `targetSize`
      3. If fewer than `minFiles` small files: return nil (nothing to compact)
      4. Download all small files, open with `parquet.OpenFile`
      5. Collect all row groups from all files via `file.RowGroups()`
      6. Merge using `parquet.MergeRowGroups(rowGroups)` — Note: use the `parquet-go` library already in go.mod. Check the exact API for the version in use (v0.25.0). If MergeRowGroups requires a schema, use the schema from the first file.
      7. Write merged result using `parquet.GenericWriter` to an in-memory buffer
      8. Upload merged file to same partition with key: `{partition}/compacted_{uuid}.parquet`
      9. Delete original small files from S3
      10. Log: "partition compacted", partition, files_merged, original_size, merged_size
      11. Record metrics: `S3FilesWritten` +1, `S3FileSize` (merged size)

    - `CompactAll(ctx context.Context) error`:
      - List all cold partitions
      - For each partition: call `CompactPartition`
      - Log and continue on per-partition errors (don't stop compaction for one failed partition)
      - Record `CompactionRuns` metric

    **Important safety rules:**
    - NEVER compact the current hour's partition (the hot partition being actively written to)
    - Compaction is idempotent: if a partition has no small files, it's a no-op
    - Delete original files ONLY after successful upload of merged file
    - If merge or upload fails, leave original files intact (no data loss)

    **Create `internal/compaction/module.go`:**
    - `Config` struct:
      - `Schedule time.Duration` (env: `COMPACTION_SCHEDULE`, default: 1*time.Hour)
      - `TargetSize int64` (env: `COMPACTION_TARGET_SIZE`, default: 128*1024*1024)
      - `MinFiles int` (env: `COMPACTION_MIN_FILES`, default: 2)
      - `Enabled bool` (env: `COMPACTION_ENABLED`, default: true)
    - `Module` struct holding `*service.CompactionService` and `*service.Scheduler`
    - `New(s3Client S3Interface, cfg Config, metrics *observability.Metrics, logger *slog.Logger) *Module`
    - `Start(ctx context.Context)` — starts scheduler
    - `Stop()` — stops scheduler
    - `RunNow(ctx context.Context) error` — manual trigger for CompactAll
  </action>
  <verify>
    - `go build ./internal/compaction/...` compiles
    - `grep "MergeRowGroups\|CopyRows\|GenericWriter" internal/compaction/internal/service/compaction_service.go` confirms Parquet merge usage
    - Verify cold partition filtering logic (current hour excluded)
  </verify>
  <done>
    Compaction service merges small Parquet files into larger ones, only operates on cold partitions, is idempotent, and records metrics. Module provides clean facade.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create compaction scheduler and wire into warehouse-sink</name>
  <files>
    internal/compaction/internal/service/scheduler.go
    cmd/warehouse-sink/main.go
  </files>
  <action>
    **Create `internal/compaction/internal/service/scheduler.go`:**
    - `Scheduler` struct:
      - `compaction *CompactionService`
      - `schedule time.Duration`
      - `logger *slog.Logger`
      - `stopCh chan struct{}`
      - `doneCh chan struct{}`
    - `NewScheduler(compaction *CompactionService, schedule time.Duration, logger *slog.Logger) *Scheduler`
    - `Start(ctx context.Context)`:
      - Launch goroutine with ticker at `schedule` interval
      - On tick: call `compaction.CompactAll(ctx)`
      - Log start/end of each compaction run with duration
      - Listen for ctx.Done() and stopCh
    - `Stop()`: close stopCh, wait for doneCh
    - `RunNow(ctx context.Context) error`: direct call to `compaction.CompactAll(ctx)`

    **Update `cmd/warehouse-sink/main.go`:**
    - Import `internal/compaction`
    - Add compaction config to Config struct
    - After S3 client creation: create compaction module
      ```go
      compactionMod := compaction.New(s3Client, cfg.Compaction, metrics, logger)
      compactionMod.Start(ctx)
      defer compactionMod.Stop()
      ```
    - On shutdown: stop compaction scheduler before stopping consumer (compaction should not run during shutdown flush)
    - Add compaction environment variables to docker-compose.yml:
      ```yaml
      COMPACTION_ENABLED: "true"
      COMPACTION_SCHEDULE: "1h"
      COMPACTION_TARGET_SIZE: "134217728"
      COMPACTION_MIN_FILES: "2"
      ```

    **Note on Hive Metastore sync:**
    After compaction, Trino needs to pick up the new file layout. The research notes that `CALL system.sync_partition_metadata()` in Trino may handle this automatically. For now, compaction just modifies S3 files. If Trino doesn't pick up changes, a post-compaction Trino SQL call can be added later. This is flagged as an open question in research — don't block on it.
  </action>
  <verify>
    - `go build ./cmd/warehouse-sink/...` compiles
    - `grep "compaction" cmd/warehouse-sink/main.go` shows compaction wired in
    - `grep "COMPACTION_SCHEDULE" docker-compose.yml` shows config in docker-compose
  </verify>
  <done>
    Compaction scheduler runs hourly inside warehouse-sink. Merges small files into 128MB+ targets. Only processes cold partitions. Wired into main with proper shutdown ordering.
  </done>
</task>

</tasks>

<verification>
- `go build ./cmd/warehouse-sink/...` compiles
- Compaction module has CompactPartition and CompactAll methods
- Cold partition filtering ensures current hour is never compacted
- Scheduler runs on configurable schedule
- Compaction wired into warehouse-sink main
- Docker Compose has compaction environment variables
</verification>

<success_criteria>
- Compaction merges small Parquet files into target size (128-256 MB)
- Only cold partitions are compacted (current hour excluded)
- Compaction runs on configurable hourly schedule
- Compaction is idempotent (safe to re-run)
- Original files deleted only after successful merge upload
- CompactionRuns metric tracks execution
- File count per partition decreases after compaction
</success_criteria>

<output>
After completion, create `.planning/phases/01-pipeline-hardening-observability-go-sdk/01-07-SUMMARY.md`
</output>
